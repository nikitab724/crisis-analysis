{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6720253d-70e2-42e6-92cb-a947825e1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter \n",
    "import numpy as np\n",
    "from spacy.lang.en import English\n",
    "from spacy.lookups import Lookups\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf60be7d-c377-4fc7-bc62-7c96bc44d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disasters': ['Earthquake', 'Seismic Event', 'Tremor', 'Tsunami', 'Tidal Wave', 'Volcanic Eruption', 'Volcanic Explosion', 'Landslide', 'Rockslide', 'Mudslide', 'Avalanche', 'Snow Avalanche', 'Sinkhole', 'Ground Collapse', 'Hurricane', 'Cyclone', 'Typhoon', 'Superstorm', 'Tornado', 'Twister', 'Blizzard', 'Snowstorm', 'Ice Storm', 'Freezing Rain', 'Hailstorm', 'Hailstorm Event', 'Dust Storm', 'Sandstorm', 'Derecho', 'Windstorm', 'Flood', 'Severe Flooding', 'Flash Flood', 'Sudden Flood', 'Storm Surge', 'Coastal Flooding', 'Seiche', 'Lake Surge', 'Drought', 'Severe Drought', 'Heatwave', 'Extreme Heatwave', 'Wildfire', 'Forest Fire', 'Brush Fire', 'Firestorm', 'Cold Snap', 'Extreme Cold', 'Polar Vortex', 'Pandemic', 'Global Pandemic', 'Epidemic', 'Disease Outbreak', 'Insect Plague', 'Locust Swarm', 'Animal Stampede', 'Asteroid Impact', 'Meteor Strike', 'Solar Flare', 'Geomagnetic Storm', 'Gamma-Ray Burst', 'Nuclear Disaster', 'Radiation Leak', 'Nuclear Meltdown', 'Chemical Spill', 'Toxic Spill', 'Hazardous Waste Leak', 'Industrial Explosion', 'Factory Explosion', 'Plant Explosion', 'Dam Failure', 'Dam Collapse', 'Blackout', 'Power Grid Failure', 'Terrorist Attack', 'Bombing Attack', 'War', 'Military Conflict', 'Civil Unrest', 'Riots', 'Mass Shooting', 'Active Shooter Incident', 'Cyberattack', 'Cybersecurity Breach', 'Deforestation', 'Forest Degradation', 'Desertification', 'Soil Erosion', 'Environmental Degradation', 'Oil Spill', 'Massive Oil Spill', 'Radioactive Contamination', 'Radiation Exposure', 'Transportation Accident', 'Major Crash', 'Structural Collapse', 'Building Collapse', 'Mine Disaster', 'Underground Collapse', 'Gas Leak Explosion', 'Pipeline Explosion', 'Chemical Explosion']}\n"
     ]
    }
   ],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "d_types = load_data(\"../data/disaster_types.json\")\n",
    "print(d_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "423f2f6d-910f-488b-bccc-a99a1abefedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns added: 102\n",
      "Sample patterns: [{'label': 'DISASTER', 'pattern': [{'LEMMA': 'earthquake'}]}, {'label': 'DISASTER', 'pattern': [{'LEMMA': 'seismic'}, {'LEMMA': 'event'}]}, {'label': 'DISASTER', 'pattern': [{'LEMMA': 'tremor'}]}, {'label': 'DISASTER', 'pattern': [{'LEMMA': 'tsunami'}]}, {'label': 'DISASTER', 'pattern': [{'LEMMA': 'tidal'}, {'LEMMA': 'wave'}]}]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])\n",
    "\n",
    "def create_training_data(file, type):\n",
    "    data = load_data(file)\n",
    "    disasters = data[\"disasters\"]\n",
    "    patterns = []\n",
    "    for item in disasters:\n",
    "        doc = nlp(item)\n",
    "        #print(item)\n",
    "        pattern_tokens = [{\"LEMMA\": token.lemma_.lower()} for token in doc]\n",
    "        #print(pattern_tokens)\n",
    "        \n",
    "        patterns.append({\"label\": type, \"pattern\": pattern_tokens})\n",
    "    return patterns\n",
    "\n",
    "# {\"label\": \"DISASTER\", \"pattern\": [{\"lemma\": \"wildfire\"}]}\n",
    "\n",
    "def generate_rules_n_lemma(patterns):\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    \n",
    "    print(f\"Total patterns added: {len(ruler.patterns)}\")\n",
    "    print(f\"Sample patterns: {ruler.patterns[:5]}\")  # Print first 5 to verify\n",
    "    \n",
    "    nlp.to_disk(\"disaster_ner\")\n",
    "\n",
    "patterns = create_training_data(\"../data/disaster_types.json\", \"DISASTER\")\n",
    "generate_rules_n_lemma(patterns)\n",
    "#Rules already generated (check app folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "76f4d8f3-1ec8-4824-9ef1-cdf00ea65dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/california_wildfires_final_data.json\")\n",
    "df = df[[\"tweet_id\", \"tweet_text\"]]\n",
    "df1 = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3f0c6a6e-cd87-45e1-b7ef-679ec5e3a802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Gizmodo: Wildfires raging through Northern California are terrifying\n",
      "Entity: wildfire | Label: DISASTER\n",
      "Entity: wildfires | Label: DISASTER\n",
      "Entity: california | Label: GPE\n",
      "Entity: wildfires | Label: DISASTER\n",
      "Entity: northern california | Label: LOC\n",
      "Entity: tidal waves | Label: DISASTER\n",
      "Entity: tokyo | Label: GPE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"disaster_ner\")\n",
    "def test_model(text):\n",
    "    doc = nlp(text.lower())\n",
    "    for ent in doc.ents:\n",
    "        print(f\"Entity: {ent.text} | Label: {ent.label_}\")\n",
    "print(df1.loc[0, \"tweet_text\"])\n",
    "\n",
    "test_model(\"RT @Cal_OES: PLS SHARE: Were capturing Wildfire response, recovery info here:\")\n",
    "test_model(\"PHOTOS: Deadly wildfires rage in California\")\n",
    "test_model(df1.loc[0, \"tweet_text\"])\n",
    "test_model(\"Huge tidal waves hit Tokyo\")\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a6467fe7-d754-421d-8689-da93944c7836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id                                         tweet_text\n",
      "0  917791044158185472  RT @Gizmodo: Wildfires raging through Northern...\n",
      "1  917791130590183424      PHOTOS: Deadly wildfires rage in California  \n",
      "2  917791291823591424  RT @Cal_OES: PLS SHARE: Were capturing wildfir...\n",
      "3  917791291823591424  RT @Cal_OES: PLS SHARE: Were capturing wildfir...\n",
      "4  917792092100988928  RT @TIME: California's raging wildfires as you...\n",
      "RT @Gizmodo: Wildfires raging through Northern California are terrifying\n",
      "PHOTOS: Deadly wildfires rage in California  \n",
      "RT @Cal_OES: PLS SHARE: Were capturing wildfire response, recovery info here:  \n",
      "RT @Cal_OES: PLS SHARE: Were capturing wildfire response, recovery info here:  \n",
      "RT @TIME: California's raging wildfires as you've never seen them before  \n",
      "             tweet_id                                         tweet_text  \\\n",
      "0  917791044158185472  RT @Gizmodo: Wildfires raging through Northern...   \n",
      "1  917791130590183424      PHOTOS: Deadly wildfires rage in California     \n",
      "2  917791291823591424  RT @Cal_OES: PLS SHARE: Were capturing wildfir...   \n",
      "3  917791291823591424  RT @Cal_OES: PLS SHARE: Were capturing wildfir...   \n",
      "4  917792092100988928  RT @TIME: California's raging wildfires as you...   \n",
      "\n",
      "     disasters              locations  \n",
      "0  [wildfires]  [northern california]  \n",
      "1  [wildfires]           [california]  \n",
      "2   [wildfire]                     []  \n",
      "3   [wildfire]                     []  \n",
      "4  [wildfires]           [california]  \n"
     ]
    }
   ],
   "source": [
    "def extract_entities(text):\n",
    "    print(text)\n",
    "    doc = nlp(text.lower())\n",
    "    disasters = []\n",
    "    locations = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DISASTER\":\n",
    "            disasters.append(ent.text)\n",
    "        elif ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]:\n",
    "            locations.append(ent.text)\n",
    "\n",
    "    return {\"disasters\": disasters, \"locations\": locations}\n",
    "\n",
    "df1.loc[:, [\"disasters\", \"locations\"]] = df1[\"tweet_text\"].apply(\n",
    "    lambda x: pd.Series(extract_entities(x))\n",
    ")\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0ac39c54-2c46-4ef8-af02-277cf144d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> RT @Gizmodo, ORG \n",
      "\n",
      "0 -> Northern California, LOC \n",
      "\n",
      "1 -> wildfires, DISASTER \n",
      "\n",
      "1 -> California, GPE \n",
      "\n",
      "2 -> PLS SHARE, ORG \n",
      "\n",
      "2 -> wildfire, DISASTER \n",
      "\n",
      "3 -> PLS SHARE, ORG \n",
      "\n",
      "3 -> wildfire, DISASTER \n",
      "\n",
      "4 -> RT @TIME, PERSON \n",
      "\n",
      "4 -> California, GPE \n",
      "\n",
      "4 -> wildfires, DISASTER \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking all entities that were found\n",
    "def extract_all_entities(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{i} -> {ent.text}, {ent.label_} \\n\")\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    extract_all_entities(df1.loc[i, \"tweet_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7fa91-672f-4fc0-bf20-aa62325298a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
